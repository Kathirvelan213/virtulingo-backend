# ── AI Services ──────────────────────────────────────────────────────────────
# Ollama (local LLM - conversation and grammar correction)
# Make sure Ollama is running: ollama serve
# Pull the model: ollama pull llama3
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# ── Supabase (PostgreSQL) ─────────────────────────────────────────────────────
# Go to: Supabase Dashboard → Project Settings → Database → Connection String → "Transaction" mode
# Use port 6543 (PgBouncer transaction pooler) — required for async/serverless workloads
#
# Format: postgresql://postgres.[project-ref]:[db-password]@aws-0-[region].pooler.supabase.com:6543/postgres
SUPABASE_DB_URL=postgresql://postgres.[project-ref]:[db-password]@aws-0-[region].pooler.supabase.com:6543/postgres

# ── Redis ─────────────────────────────────────────────────────────────────────
# Local Docker: redis://localhost:6379/0
# Upstash / Redis Cloud: rediss://default:[password]@[host]:6380
REDIS_URL=redis://localhost:6379/0

# LLM
GEMINI_MODEL=
GOOGLE_API_KEY=